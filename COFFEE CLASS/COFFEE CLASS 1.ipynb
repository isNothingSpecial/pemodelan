{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '53_coffee.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m53_coffee.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '53_coffee.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('53_coffee.csv')\n",
    "print(df)\n",
    "\n",
    "# initial data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Match ID                                      Team A Heroes  Winner\n",
      "0      4230890141  Juggernaut  Silencer  Rubick  Magnus  Monkey King  Team A\n",
      "1      4230971959   Dragon Knight  Doom  Undying  Rubick  Arc Warden  Team A\n",
      "2      4232651707  Phantom Lancer  Shadow Shaman  Doom  Outworld ...  Team A\n",
      "3      4232732529     Lich  Bounty Hunter  Lone Druid  Rubick  Slark  Team A\n",
      "4      4234538318       Sand King  Lich  Gyrocopter  Io  Monkey King  Team A\n",
      "...           ...                                                ...     ...\n",
      "10114  6897302061  Huskar  Disruptor  Monkey King  Dawnbreaker  P...  Team A\n",
      "10115  6898635544  Mirana  Pudge  Outworld Devourer  Brewmaster  ...  Team B\n",
      "10116  6898745371  Death Prophet  Templar Assassin  Leshrac  Undy...  Team B\n",
      "10117  6900923689  Earthshaker  Mirana  Razor  Arc Warden  Pangolier  Team A\n",
      "10118  6901058238  Templar Assassin  Disruptor  Void Spirit  Dawn...  Team A\n",
      "\n",
      "[10119 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#select needed columns\n",
    "\n",
    "df1 = pd.DataFrame(df, columns=[\"Match ID\", \"Team A Heroes\", \"Winner\"])\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         match_id                                              hero1  result\n",
      "0      4230890141  Juggernaut  Silencer  Rubick  Magnus  Monkey King  Team A\n",
      "1      4230971959   Dragon Knight  Doom  Undying  Rubick  Arc Warden  Team A\n",
      "2      4232651707  Phantom Lancer  Shadow Shaman  Doom  Outworld ...  Team A\n",
      "3      4232732529     Lich  Bounty Hunter  Lone Druid  Rubick  Slark  Team A\n",
      "4      4234538318       Sand King  Lich  Gyrocopter  Io  Monkey King  Team A\n",
      "...           ...                                                ...     ...\n",
      "10114  6897302061  Huskar  Disruptor  Monkey King  Dawnbreaker  P...  Team A\n",
      "10115  6898635544  Mirana  Pudge  Outworld Devourer  Brewmaster  ...  Team B\n",
      "10116  6898745371  Death Prophet  Templar Assassin  Leshrac  Undy...  Team B\n",
      "10117  6900923689  Earthshaker  Mirana  Razor  Arc Warden  Pangolier  Team A\n",
      "10118  6901058238  Templar Assassin  Disruptor  Void Spirit  Dawn...  Team A\n",
      "\n",
      "[10119 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#rename columns\n",
    "\n",
    "df2 = pd.DataFrame(df1)\n",
    "df2.rename(columns={'Match ID': 'match_id', 'Team A Heroes': 'hero1', 'Winner': 'result'}, inplace=True)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         match_id                                              hero1  hero2  \\\n",
      "0      4230890141  Juggernaut  Silencer  Rubick  Magnus  Monkey King      0   \n",
      "1      4230971959   Dragon Knight  Doom  Undying  Rubick  Arc Warden      0   \n",
      "2      4232651707  Phantom Lancer  Shadow Shaman  Doom  Outworld ...      0   \n",
      "3      4232732529     Lich  Bounty Hunter  Lone Druid  Rubick  Slark      0   \n",
      "4      4234538318       Sand King  Lich  Gyrocopter  Io  Monkey King      0   \n",
      "...           ...                                                ...    ...   \n",
      "10114  6897302061  Huskar  Disruptor  Monkey King  Dawnbreaker  P...      0   \n",
      "10115  6898635544  Mirana  Pudge  Outworld Devourer  Brewmaster  ...      0   \n",
      "10116  6898745371  Death Prophet  Templar Assassin  Leshrac  Undy...      0   \n",
      "10117  6900923689  Earthshaker  Mirana  Razor  Arc Warden  Pangolier      0   \n",
      "10118  6901058238  Templar Assassin  Disruptor  Void Spirit  Dawn...      0   \n",
      "\n",
      "       hero3  hero4  hero5  result  \n",
      "0          0      0      0  Team A  \n",
      "1          0      0      0  Team A  \n",
      "2          0      0      0  Team A  \n",
      "3          0      0      0  Team A  \n",
      "4          0      0      0  Team A  \n",
      "...      ...    ...    ...     ...  \n",
      "10114      0      0      0  Team A  \n",
      "10115      0      0      0  Team B  \n",
      "10116      0      0      0  Team B  \n",
      "10117      0      0      0  Team A  \n",
      "10118      0      0      0  Team A  \n",
      "\n",
      "[10119 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#add more columns for 5 heroes\n",
    "\n",
    "df3 = pd.DataFrame(df2)\n",
    "df3.insert(2, 'hero2', 0)\n",
    "df3.insert(3, 'hero3', 0)\n",
    "df3.insert(4, 'hero4', 0)\n",
    "df3.insert(5, 'hero5', 0)\n",
    "\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         match_id             hero1             hero2              hero3  \\\n",
      "0      4230890141        Juggernaut          Silencer             Rubick   \n",
      "1      4230971959     Dragon Knight              Doom            Undying   \n",
      "2      4232651707    Phantom Lancer     Shadow Shaman               Doom   \n",
      "3      4232732529              Lich     Bounty Hunter         Lone Druid   \n",
      "4      4234538318         Sand King              Lich         Gyrocopter   \n",
      "...           ...               ...               ...                ...   \n",
      "10114  6897302061            Huskar         Disruptor        Monkey King   \n",
      "10115  6898635544            Mirana             Pudge  Outworld Devourer   \n",
      "10116  6898745371     Death Prophet  Templar Assassin            Leshrac   \n",
      "10117  6900923689       Earthshaker            Mirana              Razor   \n",
      "10118  6901058238  Templar Assassin         Disruptor        Void Spirit   \n",
      "\n",
      "                   hero4         hero5 result  \n",
      "0                 Magnus   Monkey King      1  \n",
      "1                 Rubick    Arc Warden      1  \n",
      "2      Outworld Devourer  Earth Spirit      1  \n",
      "3                 Rubick         Slark      1  \n",
      "4                     Io   Monkey King      1  \n",
      "...                  ...           ...    ...  \n",
      "10114        Dawnbreaker  Primal Beast      1  \n",
      "10115         Brewmaster          Tusk      0  \n",
      "10116            Undying  Nyx Assassin      0  \n",
      "10117         Arc Warden     Pangolier      1  \n",
      "10118        Dawnbreaker  Primal Beast      1  \n",
      "\n",
      "[10119 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#loop for each row, adding heroes to new columns\n",
    "\n",
    "df4 = pd.DataFrame(df3)\n",
    "\n",
    "for i in range(len(df4)):\n",
    "    if (df4.loc[i,'result'] == \"Team A\"):\n",
    "        df4.loc[i,'result'] = 1\n",
    "    elif (df4.loc[i,'result'] == \"Team B\"):\n",
    "        df4.loc[i,'result'] = 0\n",
    "        \n",
    "    data=df4.loc[i,'hero1']\n",
    "    data=data.split(\"  \")\n",
    "    df4.loc[i,'hero1']=data[0]\n",
    "    df4.loc[i,'hero2']=data[1]\n",
    "    df4.loc[i,'hero3']=data[2]\n",
    "    df4.loc[i,'hero4']=data[3]\n",
    "    df4.loc[i,'hero5']=data[4]\n",
    "    \n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make unique ID for each hero\n",
    "df5 = pd.DataFrame(df4, columns=[\"hero1\", \"hero2\", \"hero3\", \"hero4\", \"hero5\"])\n",
    "\n",
    "allheroes=[]\n",
    "for i in range(len(df5)):\n",
    "    allheroes.append(df5.loc[i,'hero1'])\n",
    "    allheroes.append(df5.loc[i,'hero2'])\n",
    "    allheroes.append(df5.loc[i,'hero3'])\n",
    "    allheroes.append(df5.loc[i,'hero4'])\n",
    "    allheroes.append(df5.loc[i,'hero5'])\n",
    "    \n",
    "allheroes = list(dict.fromkeys(allheroes))\n",
    "allheroes = sorted(allheroes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         match_id hero1 hero2 hero3 hero4 hero5 result\n",
      "0      4230890141    78   123   118    90    96      1\n",
      "1      4230971959    62    61   144   118    39      1\n",
      "2      4232651707   109   122    61   106    64      1\n",
      "3      4232732529    83    45    87   118   126      1\n",
      "4      4234538318   119    83    72    76    96      1\n",
      "...           ...   ...   ...   ...   ...   ...    ...\n",
      "10114  6897302061    74    60    96    57   111      1\n",
      "10115  6898635544    95   113   106    46   142      0\n",
      "10116  6898745371    59   134    82   144   102      0\n",
      "10117  6900923689    65    95   116    39   107      1\n",
      "10118  6901058238   134    60   150    57   111      1\n",
      "\n",
      "[10119 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#replace hero names with hero id\n",
    "\n",
    "df6 = pd.DataFrame(df4)\n",
    "\n",
    "for i in range(len(df6)):\n",
    "    x=(df6.loc[i,'hero1'])\n",
    "    xx=allheroes.index(x, 0, len(allheroes))\n",
    "    df6.loc[i,'hero1'] = xx\n",
    "    \n",
    "    y=(df6.loc[i,'hero2'])\n",
    "    yy=allheroes.index(y, 0, len(allheroes))\n",
    "    df6.loc[i,'hero2'] = yy\n",
    "    \n",
    "    z=(df6.loc[i,'hero3'])\n",
    "    zz=allheroes.index(z, 0, len(allheroes))\n",
    "    df6.loc[i,'hero3'] = zz\n",
    "    \n",
    "    c=(df6.loc[i,'hero4'])\n",
    "    cc=allheroes.index(c, 0, len(allheroes))\n",
    "    df6.loc[i,'hero4'] = cc\n",
    "    \n",
    "    d=(df6.loc[i,'hero5'])\n",
    "    dd=allheroes.index(d, 0, len(allheroes))\n",
    "    df6.loc[i,'hero5'] = dd\n",
    "\n",
    "print(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.to_csv(r'./finaldata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hero1</th>\n",
       "      <th>hero2</th>\n",
       "      <th>hero3</th>\n",
       "      <th>hero4</th>\n",
       "      <th>hero5</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>123</td>\n",
       "      <td>118</td>\n",
       "      <td>90</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>144</td>\n",
       "      <td>118</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>122</td>\n",
       "      <td>61</td>\n",
       "      <td>106</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83</td>\n",
       "      <td>45</td>\n",
       "      <td>87</td>\n",
       "      <td>118</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119</td>\n",
       "      <td>83</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hero1  hero2  hero3  hero4  hero5  result\n",
       "0     78    123    118     90     96       1\n",
       "1     62     61    144    118     39       1\n",
       "2    109    122     61    106     64       1\n",
       "3     83     45     87    118    126       1\n",
       "4    119     83     72     76     96       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./finaldata.csv')\n",
    "data = data.drop(['match_id'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('result',axis=1)\n",
    "y = data[\"result\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5928853754940712"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_predict = nb.predict(X_test)\n",
    "\n",
    "nb_acc_score = accuracy_score(y_test, nb_predict)\n",
    "nb_acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5948616600790514"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_params = {'n_neighbors': range(1, 16)}\n",
    "knn_grid = GridSearchCV(knn, knn_params, cv=5)\n",
    "knn_grid.fit(X_train, y_train)\n",
    "best_n_neighbors = knn_grid.best_params_['n_neighbors']\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_predict = knn.predict(X_test)\n",
    "\n",
    "knn_acc_score = accuracy_score(y_test, knn_predict)\n",
    "knn_acc_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3228c686c13c3891ac7b9546204ca4390d65863877b8863b460a3da758c70c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
